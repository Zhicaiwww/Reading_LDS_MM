# Reading\_LDS_MM
This is a list of papers shared in LDS multi_media Group
## Table of contents
- [Survey Paper](#1)
- [Model and Architecture](#2)
- [Causality in Computer Vision](#3)
- [Video Representation Learning](#4)
- [Multi-Model](#5)


## <h2 id="1">Survey Paper</h2>
- [Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications](http://arxiv.org/abs/2008.02793)(2020)

## <h2 id="2">Model and Architecture</h2>
- [V4D:4D convolutional neural networks for video-level representation learning](http://arxiv.org/abs/2002.07442)(2020)
- [Non-local Neural Networks](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf)(2018CVPR)
- [X3D: Expanding Architectures for Efficient Video Recognition](http://arxiv.org/abs/2004.04730)(2020)
- [Selective kernel networks](https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Selective_Kernel_Networks_CVPR_2019_paper.html)(2019CVPR)
- [SpeedNet: Learning the Speediness in Videos](http://arxiv.org/abs/2004.06130)(2020)
- [BAM: Bottleneck attention module](http://arxiv.org/abs/1807.06514)(2018)
- [RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition](https://rubiksnet.stanford.edu/)(2020ECCV)
- [Cbam: Convolutional block attention module](https://openaccess.thecvf.com/content_ECCV_2018/html/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.html)(2018ECCV)
- [Gate-shift networks for video action recognition](https://openaccess.thecvf.com/content_CVPR_2020/html/Sudhakaran_Gate-Shift_Networks_for_Video_Action_Recognition_CVPR_2020_paper.html)(2020CVPR)
- [Smallbignet: Integrating core and contextual views for video classification](https://arxiv.org/abs/2006.14582)(2020)
- [Rotate to Attend: Convolutional triplet attention module](http://arxiv.org/abs/2010.03045)(2020)

## <h2 id="3">Causality in Computer Vision</h2>
- [The Blessings of Unlabeled Background in Untrimmed Videos](http://arxiv.org/abs/2103.13183)(2021)
- [The Blessings of Multiple Causes](https://arxiv.org/abs/1805.06826)(2019)
- [Causal Attention for Vision-Language Tasks](https://arxiv.org/abs/2103.03493)(2021)

## <h2 id="4">Video Representation Learning</h2>
- [Video Representation Learning by Recognizing Temporal Transformations](http://arxiv.org/abs/2007.10730)(2020ECCV)
- [Evolving losses for unsupervised video representation learning](https://openaccess.thecvf.com/content_CVPR_2020/html/Piergiovanni_Evolving_Losses_for_Unsupervised_Video_Representation_Learning_CVPR_2020_paper.html)(2020CVPR)
- [Memory-Augmented Dense Predictive Coding for Video Representation Learning](http://arxiv.org/abs/2008.01065)(2020)

## <h2 id="5">Multi-Model</h2>
- [Large-Scale Few-Shot Learning via Multi-modal Knowledge Discovery](https://link.springer.com/chapter/10.1007/978-3-030-58607-2_42)(2020ECCV)
- [Cross-modal interaction networks for query-based moment retrieval in videos](http://arxiv.org/abs/1607.06215)(2019SIGIR)
- [Audio-Visual Instance Discrimination with Cross-Modal Agreement](http://arxiv.org/abs/2004.12943)(2020)
